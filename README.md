Этот проект представляет собой разработку модели машинного перевода с русского на алеутский язык. Модель основана на архитектуре MarianMT из библиотеки transformers и обучена на пользовательском наборе данных, содержащем пары переводов «русский — алеутский». Данные для обучения созданы на основе «Aleut Grammar» Кнута Бергсланда с добавлением производных и заимствованных слов там, где оригинальная лексика отсутствует.

Цель проекта — автоматизировать перевод с русского на алеутский язык, сохраняя грамматические особенности и лексическую точность алеутского языка.

# Задача проекта
Разработать программу, которая:

- Принимает на вход файл с русскими фразами и их переводами на алеутский язык;
- Обучает модель машинного перевода для автоматического перевода с русского на алеутский;
- Сохраняет обученную модель для дальнейшего использования.

### Исходные данные
Классификатор (russian_aleut_dataset.csv) доступных переводов с полями:
* Russian — Русская фраза или слово;
* Aleut — Перевод на алеутский язык;
* Tag — Метка (0 — нейтрально, 1 — настоящее, 2 — прошедшее, 3 — вопросительно, 4 — локатив);
* Note (опционально) — Пометка ("derived" для производных слов, "borrowed" для заимствований).

---

Код сохраняет модель в папку Marian_aleut_model и создаёт архив Marian_aleut_model.zip.

## Принцип работы кода

В своём коде я использую библиотеку transformers для обучения модели MarianMT и pandas для работы с данными в формате CSV. Код включает в себя несколько этапов, каждый из которых выполняет определённую задачу в процессе обучения модели. Код запускался в Google Colab (Python 3.11).

### Transformers
Так как стандартная модель MarianMT (Helsinki-NLP/opus-mt-ru-en) не поддерживает алеутский язык, было принято решение адаптировать её под задачу. В токенизатор добавлен специальный символ ẍ, характерный для алеутской письменности, и модель была дообучена на пользовательском наборе данных russian_aleut_dataset.csv. Это решение масштабируемо, так как при необходимости можно увеличить объём данных для улучшения качества перевода.

### О датасете
Перед основным кодом мы подготавливаем файл russian_aleut_dataset.csv. Данные загружаются в pandas.DataFrame, затем преобразуются в формат datasets.Dataset для обучения. Пары русский-алеутский разделяются на обучающую (90%) и тестовую (10%) выборки с помощью метода train_test_split.

## Структура кода
1. Импорт библиотек (transformers, torch, pandas, datasets);
2. Загрузка и подготовка данных из файла russian_aleut_dataset.csv;
3. Инициализация модели и токенизатора MarianMT;
4. Функция предобработки данных preprocess_function(examples) для токенизации;
5. Настройка параметров обучения TrainingArguments;
6. Создание и запуск Trainer для обучения модели;
7. Сохранение модели в папку Marian_aleut_model и создание архива;
8. Функция тестирования translate(text) для проверки модели.
   
## Функции
1. **preprocess_function(examples) -> dict**

    Эта функция токенизирует входные данные и подготавливает их для обучения модели.

    Основные шаги:

    * Токенизация русских фраз (source) с максимальной длиной 128 токенов;
    * Токенизация алеутских переводов (target) в режиме целевого токенизатора;
    * Добавление меток (labels) в выходной словарь для обучения.
      
2. **translate(text) -> str**
   
   Функция выполняет перевод текста с русского на алеутский с использованием обученной модели.

   Основные шаги:

    * Токенизация входного текста с возвращением тензоров PyTorch;
    * Генерация перевода с использованием параметров max_length=128, num_beams=5, early_stopping=True;
    * Декодирование токенов в строку с удалением специальных символов;
    * Постобработка пробелов перед ẍ для корректного отображения.
